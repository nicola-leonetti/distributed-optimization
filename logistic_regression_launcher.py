'''
Solution of a cost-coupled problem: logistic regression for
classification.

Each agent has a certain number of randomly generated points, labeled 1 
or -1. The points are generated by agents according to a multivariate 
normal distribution, with different mean and covariance for the two 
labels.

The results are obtained using the following algorithms:
- Gradient Tracking
- ADMM-Tracking Gradient
- GIANT-ADMM

The results are saved in some files for further analysis.
'''

import dill as pickle
import numpy as np
from mpi4py import MPI
from disropt.agents import Agent
from disropt.algorithms import SubgradientMethod, GradientTracking, DualDecomposition
from disropt.functions import Variable, SquaredNorm, Logistic
from disropt.utils.graph_constructor import binomial_random_graph, metropolis_hastings
from disropt.problems import Problem

from admm_tracking_gradient import ADMMTrackingGradient
from giant_admm import GIANTADMM

NN = MPI.COMM_WORLD.Get_size()
agent_id = MPI.COMM_WORLD.Get_rank()

# Genero un grafo random ma comune a tutti gli agenti
Adj = binomial_random_graph(NN, p=0.3, seed=1)
W = metropolis_hastings(Adj)

# Genero numeri random per ogni agente
np.random.seed(10*agent_id)

# Genero i parametri di una gaussiana
mu = (np.array([0, 0]).transpose(), np.array([3, 2]).transpose())
sigma = (np.eye(2), np.eye(2))

# dimension of sample space
dim = mu[0].shape[0]

# number of samples (min 2 max 5 for each label)
number_of_samples = (np.random.randint(2, 6), np.random.randint(2, 6))

# Parametro di regolarizzazione
C = 10

# Genera i punti
points = np.zeros((dim, number_of_samples[0] + number_of_samples[1]))
points[:, 0:number_of_samples[0]] = np.random.multivariate_normal(
    mu[0], sigma[0], number_of_samples[0]).transpose()
points[:, number_of_samples[0]:] = np.random.multivariate_normal(
    mu[1], sigma[1], number_of_samples[1]).transpose()

# Genera i label
labels = np.ones((sum(number_of_samples), 1))
labels[number_of_samples[0]:] = -labels[number_of_samples[0]:]

# Genera la funzione costo
z = Variable(dim+1)
A = np.ones((dim+1, 1))
A[-1] = 0
obj_func = (C / (2 * NN)) * SquaredNorm(A @ z)

for j in range(sum(number_of_samples)):
    e_j = np.zeros((sum(number_of_samples), 1))
    e_j[j] = 1
    A_j = np.vstack((points @ e_j, 1))
    obj_func += Logistic(- labels[j] * A_j @ z)

#####################
# Distributed algorithms
#####################

# Inizializzo agente e problema
agent = Agent(
    in_neighbors=np.nonzero(Adj[agent_id, :])[0].tolist(),
    out_neighbors=np.nonzero(Adj[:, agent_id])[0].tolist(),
    in_weights=W[agent_id, :].tolist()
)
pb = Problem(obj_func)
agent.set_problem(pb)

# instantiate the algorithms
x0 = 5*np.random.rand(dim+1, 1)

iterations = 2000
def GT_stepsize(k): return 0.001


# ADMM-Tracking Gradient parameters
ADMM_gamma = 0.9
ADMM_rho = 0.3
ADMM_alpha = 0.9
def ADMM_stepsize(k): return 0.5


# GIANT-ADMM parameters
GIANT_gamma = 0.5
GIANT_rho = 0.9
GIANT_alpha = 0.9
def GIANT_stepsize(k): return 0.5


gradient_tracking = GradientTracking(
    agent=agent,
    initial_condition=x0,
    enable_log=True
)

ADMM_tracking_gradient = ADMMTrackingGradient(
    agent=agent,
    initial_condition=x0,
    initial_z={i: 10*np.random.rand(2*(dim+1), 1) for i in agent.in_neighbors},
    gamma=GIANT_gamma,
    rho=GIANT_rho,
    alpha=GIANT_alpha,
    enable_log=True
)

GIANT_ADMM = GIANTADMM(
    agent=agent,
    initial_condition=x0,
    initial_z={i: 10*np.random.rand(2*(dim+1), 1) for i in agent.in_neighbors},
    gamma=GIANT_gamma,
    rho=GIANT_rho,
    alpha=GIANT_alpha,
    enable_log=True
)

# run the algorithms
gt_sequence = gradient_tracking.run(
    iterations=iterations, stepsize=GT_stepsize)
ADMM_sequence = ADMM_tracking_gradient.run(
    iterations=iterations, stepsize=ADMM_stepsize)
# GIANT_sequence = GIANT_ADMM.run(iterations=iterations, stepsize=GIANT_stepsize)

print(f"Gradient tracking: agent {agent_id}: {
      gradient_tracking.get_result().flatten()}")
print(f"ADMM-Tracking Gradient: agent {agent_id}: {
    ADMM_tracking_gradient.get_result().flatten()}")
# print(f"GIANT-ADMM: agent {agent_id}: {GIANT_ADMM.get_result().flatten()}")

# Salvo numero di agenti, dimensione dello spazio e iterazioni in "info.pkl
if agent_id == 0:
    with open('info.pkl', 'wb') as output:
        pickle.dump({'N': NN, 'size': dim+1, 'iterations': iterations},
                    output, pickle.HIGHEST_PROTOCOL)

# Salvo la funzione relativa all'agente i-esimo in "agent_i_func.pkl"
with open(f'agent_{agent_id}_func.pkl', 'wb') as output:
    pickle.dump(obj_func, output, pickle.HIGHEST_PROTOCOL)

# Salvo la sequenza di soluzioni del Gradient-Tracking in "agent_i_seq_gradtr.npy"
np.save(f"agent_{agent_id}_seq_gradtr.npy", np.squeeze(gt_sequence))
np.save(f"agent_{agent_id}_seq_admm.npy", np.squeeze(ADMM_sequence))
# np.save(f"agent_{agent_id}_seq_giant.npy", np.squeeze(GIANT_sequence))
